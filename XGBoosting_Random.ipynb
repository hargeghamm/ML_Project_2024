{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## In this notebook, we are going to explore the XGBoosting classifier's hyperparameter space, take the best configuration of hyperparameters based on UCB algorithmy, compare with randomly chosen hyperparameter configuration, compare their performance and evaluate the validation error."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import necessary libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import math\n",
    "import random\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns \n",
    "import xlrd\n",
    "from sklearn.model_selection import train_test_split\n",
    "import xgboost as xgb \n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "from utils import *"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Read the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_excel('Titanic_dataset.xls') "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preprocess the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pclass          0\n",
      "survived        0\n",
      "name            0\n",
      "sex             0\n",
      "age           263\n",
      "sibsp           0\n",
      "parch           0\n",
      "ticket          0\n",
      "fare            1\n",
      "cabin        1014\n",
      "embarked        2\n",
      "boat          823\n",
      "body         1188\n",
      "home.dest     564\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "na_value = data.isna()\n",
    "na_counts = na_value.sum()\n",
    "print(na_counts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "columns_to_drop = ['name', 'ticket', 'cabin', 'boat', 'body', 'home.dest']\n",
    "data = data.drop(columns_to_drop, axis=1)\n",
    "\n",
    "data['age'].fillna(data['age'].median(), inplace=True)\n",
    "data['fare'].fillna(data['fare'].mean(), inplace=True)\n",
    "data['embarked'].fillna(data['embarked'].mode()[0], inplace=True)\n",
    "\n",
    "data = pd.get_dummies(data, columns=['sex', 'embarked'])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Split the data into train and test sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = data.drop('survived', axis=1)\n",
    "y = data['survived']\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define the hyperparameter space for XGBoosting algorithm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7000"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "learning_rates = [0.01, 0.05, 0.1, 0.2, 0.3, 0.4, 0.5]\n",
    "n_estimators = [50, 100, 150, 200, 250, 300, 350, 400, 450, 500]\n",
    "max_depths = [3, 5, 7, 9]\n",
    "reg_alpha = [0, 0.1, 0.5, 1, 2]\n",
    "reg_lambda = [0, 0.1, 0.5, 1, 2]\n",
    "\n",
    "param_space_XGB = []\n",
    "\n",
    "for lr in learning_rates:\n",
    "    for ne in n_estimators:\n",
    "        for md in max_depths:\n",
    "            for ra in reg_alpha:\n",
    "                for rl in reg_lambda:\n",
    "                    config = {\n",
    "                        'learning_rate': lr,\n",
    "                        'n_estimators': ne,\n",
    "                        'max_depth': md,\n",
    "                        'reg_alpha': ra,\n",
    "                        'reg_lambda': rl\n",
    "                    }\n",
    "                    param_space_XGB.append(config)\n",
    "\n",
    "len(param_space_XGB)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluate the UCB on XGBoosting and Random Strategy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset: Titanic Dataset\n",
      "\n",
      "UCB Strategy on XGBoosting:\n",
      "Best validation error: 0.1984732824427481\n",
      "Best hyperparameter configuration: {'learning_rate': 0.01, 'n_estimators': 50, 'max_depth': 9, 'reg_alpha': 0, 'reg_lambda': 0.5}\n",
      "\n",
      "Random Strategy on XGBoosting:\n",
      "Best validation error: 0.23664122137404575\n",
      "Best hyperparameter configuration: {'learning_rate': 0.1, 'n_estimators': 50, 'max_depth': 5, 'reg_alpha': 0.1, 'reg_lambda': 1}\n"
     ]
    }
   ],
   "source": [
    "best_config_ucb, best_config_random_XGB, pred_rand_XGB = XGBoost_Random(X_train, y_train, X_test, y_test, param_space_XGB)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train the final XGBoosting model using the best hyperparameters from UCB strategy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-2 {color: black;background-color: white;}#sk-container-id-2 pre{padding: 0;}#sk-container-id-2 div.sk-toggleable {background-color: white;}#sk-container-id-2 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-2 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-2 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-2 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-2 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-2 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-2 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-2 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-2 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-2 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-2 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-2 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-2 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-2 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-2 div.sk-item {position: relative;z-index: 1;}#sk-container-id-2 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-2 div.sk-item::before, #sk-container-id-2 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-2 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-2 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-2 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-2 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-2 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-2 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-2 div.sk-label-container {text-align: center;}#sk-container-id-2 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-2 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-2\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
       "              colsample_bylevel=None, colsample_bynode=None,\n",
       "              colsample_bytree=None, early_stopping_rounds=None,\n",
       "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
       "              gamma=None, gpu_id=None, grow_policy=None, importance_type=None,\n",
       "              interaction_constraints=None, learning_rate=0.01, max_bin=None,\n",
       "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
       "              max_delta_step=None, max_depth=9, max_leaves=None,\n",
       "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
       "              n_estimators=50, n_jobs=None, num_parallel_tree=None,\n",
       "              predictor=None, random_state=None, ...)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-2\" type=\"checkbox\" checked><label for=\"sk-estimator-id-2\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">XGBClassifier</label><div class=\"sk-toggleable__content\"><pre>XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
       "              colsample_bylevel=None, colsample_bynode=None,\n",
       "              colsample_bytree=None, early_stopping_rounds=None,\n",
       "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
       "              gamma=None, gpu_id=None, grow_policy=None, importance_type=None,\n",
       "              interaction_constraints=None, learning_rate=0.01, max_bin=None,\n",
       "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
       "              max_delta_step=None, max_depth=9, max_leaves=None,\n",
       "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
       "              n_estimators=50, n_jobs=None, num_parallel_tree=None,\n",
       "              predictor=None, random_state=None, ...)</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
       "              colsample_bylevel=None, colsample_bynode=None,\n",
       "              colsample_bytree=None, early_stopping_rounds=None,\n",
       "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
       "              gamma=None, gpu_id=None, grow_policy=None, importance_type=None,\n",
       "              interaction_constraints=None, learning_rate=0.01, max_bin=None,\n",
       "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
       "              max_delta_step=None, max_depth=9, max_leaves=None,\n",
       "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
       "              n_estimators=50, n_jobs=None, num_parallel_tree=None,\n",
       "              predictor=None, random_state=None, ...)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "XGB_UCB_test = xgb.XGBClassifier(**best_config_ucb)\n",
    "XGB_UCB_test.fit(X_train, y_train) "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluate performance on the test set using the best hyperparameters from UCB strategy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_predictions_ucb_XGB = XGB_UCB_test.predict(X_test)\n",
    "test_accuracy_ucb = accuracy_score(y_test, test_predictions_ucb_XGB)\n",
    "test_precision_ucb = precision_score(y_test, test_predictions_ucb_XGB)\n",
    "test_recall_ucb = recall_score(y_test, test_predictions_ucb_XGB)\n",
    "test_f1_ucb = f1_score(y_test, test_predictions_ucb_XGB)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluate performance on the test set using the best hyperparameters from random strategy\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_predictions_rand_XGB = pred_rand_XGB \n",
    "test_accuracy_random = accuracy_score(y_test, test_predictions_rand_XGB)\n",
    "test_precision_random = precision_score(y_test, test_predictions_rand_XGB)\n",
    "test_recall_random = recall_score(y_test, test_predictions_rand_XGB)\n",
    "test_f1_random = f1_score(y_test, test_predictions_rand_XGB)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Compare the performances of UCB-selected and Random-Selected hyperparameters for XGBoosting  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "UCB-selected hyperparameters for XGBoosting:  {'learning_rate': 0.01, 'n_estimators': 50, 'max_depth': 9, 'reg_alpha': 0, 'reg_lambda': 0.5}\n",
      "UCB-selected performance:\n",
      "  - Accuracy: 0.8015267175572519\n",
      "  - Precision: 0.875\n",
      "  - Recall: 0.652542372881356\n",
      "  - F1-score: 0.7475728155339806\n",
      "\n",
      "Random-selected hyperparameters for XGBoosting:  {'learning_rate': 0.1, 'n_estimators': 50, 'max_depth': 5, 'reg_alpha': 0.1, 'reg_lambda': 1}\n",
      "Random-selected performance:\n",
      "  - Accuracy: 0.7633587786259542\n",
      "  - Precision: 0.85\n",
      "  - Recall: 0.576271186440678\n",
      "  - F1-score: 0.686868686868687\n"
     ]
    }
   ],
   "source": [
    "print(\"UCB-selected hyperparameters for XGBoosting: \", best_config_ucb)\n",
    "print(\"UCB-selected performance:\")\n",
    "print(f\"  - Accuracy: {test_accuracy_ucb}\")\n",
    "print(f\"  - Precision: {test_precision_ucb}\")\n",
    "print(f\"  - Recall: {test_recall_ucb}\")\n",
    "print(f\"  - F1-score: {test_f1_ucb}\")\n",
    "\n",
    "print(\"\\nRandom-selected hyperparameters for XGBoosting: \", best_config_random_XGB)\n",
    "print(\"Random-selected performance:\")\n",
    "print(f\"  - Accuracy: {test_accuracy_random}\")\n",
    "print(f\"  - Precision: {test_precision_random}\")\n",
    "print(f\"  - Recall: {test_recall_random}\")\n",
    "print(f\"  - F1-score: {test_f1_random}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.1"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
